{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MTH8408 : Méthodes d'optimisation et contrôle optimal\n",
    " ## Laboratoire 6: Optimisation avec contraintes et contrôle optimal\n",
    "Tangi Migot et Dominique Orban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce lab, on va utiliser une branche particulière (en cours de développement) du package PDENLPModels.jl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "] add https://github.com/JuliaSmoothOptimizers/PDENLPModels.jl#lab_poly_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PDENLPModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gridap, NLPModelsIpopt, Plots, Printf, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "] status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1: Commande optimale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exercice, on considère le problème de gestion de portefeuille vu en cours:\n",
    "$$\n",
    "\\max_{x,u} \\int_0^T (1-u(t))x(t) dt, \\quad x(0)=x_0, \\dot{x}(t) = \\gamma u(t) x(t), \\quad 0 \\leq u(t) \\leq 1\n",
    "$$\n",
    "modélisé avec `PDENLPModels`. Compléter l'appel à la fonction `GridapOptimalControl1DNLPModel` avec `n = 100`, `T = 1`, `γ = 3` et `x0 = 0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=function GridapOptimalControl1DNLPModel(f, con, domain, n; \n",
    "                                       x0 = nothing, xf = nothing, \n",
    "                                       umin = nothing, umax = nothing) =#\n",
    "# \n",
    "# n est la taille de la discrétisation (entier)\n",
    "n = \n",
    "# le domain au format (t₀, T)\n",
    "domain = \n",
    "# x0 est la valeur initiale de x (nombre)\n",
    "x0 =  \n",
    "# umin et umax sont des fonctions qui représentent les bornes:\n",
    "umin = t -> \n",
    "umax = t -> \n",
    "#La fonction objectif sous l'intégrale:\n",
    "f(x, u) = \n",
    "#Le membre de droite de l'EDO:\n",
    "γ = \n",
    "con(x, u) = \n",
    "nlp = GridapOptimalControl1DNLPModel(f, con, domain, n; x0 = x0, umin = umin, umax = umax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur ce type de NLPModel, on peut avoir accès à la taille de la discrétisation de x et de u avec les attributs `nvar_pde` et `nvar_con`. Compléter le test suivant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nU = nlp.pdemeta.nvar_pde\n",
    "nUcon = nlp.pdemeta.nvar_con\n",
    "@test nU == n\n",
    "@test nUcon == n+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Résoudre et affichage\n",
    "Résoudre le NLPModel avec `ipopt` en partant du vecteur 0. Puis, compléter le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xu0 = # à compléter\n",
    "stats = ipopt(nlp, x0 = xu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@test :first_order == stats.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher la solution x et la solution u avec un titre, pas de légende, et le temps en abscisse.\n",
    "\n",
    "Vous pouvez utiliser la fonction `LinRange` pour gérer le temps en abscisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsol = stats.solution[1:nU];\n",
    "usol = stats.solution[nU+1:nU+nUcon];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour afficher l'adjoint, compléter la fonction `adjoint_function_final_condition` et afficher le rendu en fonction du temps comme sur les graphes précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function adjoint_function_final_condition(domain, n, mul, xf)\n",
    "# domain et n, cf. l'appel GridapOptimalControlNLPModel\n",
    "# mul: le multiplicateur de Lagrange renvoyé par Ipopt\n",
    "# xf: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Bang-bang\n",
    "A quelle instant `t` se situe le changement de trajectoire?\n",
    "\n",
    "Proposer une nouvelle valeur de γ où le controle n'est plus \"bang-bang\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Proposer une modification continue de γ et recommencer les graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2: Le réservoir\n",
    "\n",
    "Dans ce dernier exercice, on considère le problème de réservoir, où on impose les contraintes $x_1(1)=γ$ et $x_1(t)\\leq γ$.\n",
    "\n",
    "$$\n",
    "\\max_{x_1,x_2,u} x_2(T), \\quad \\dot{x_1} = -x_1 + u, \\dot{x_2} = x_1, x_1(0) = x_2(0) = 0.\n",
    "$$\n",
    "Compléter l'appel à la fonction `bounded_2D_optimal_control` avec $n=10$ et $γ = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function 2D_bounded_optimal_control(domain, n, f, con1, con2, umin, umax, xmin, xmax, x0, xf)\n",
    "#n et domain comme dans l'exercice précédent.\n",
    "n = \n",
    "domain = \n",
    "γ = \n",
    "#le vecteur de donné initial\n",
    "x0 = zeros(2)\n",
    "#le nombre pour la contrainte finale sur x_1\n",
    "xf = γ\n",
    "#umin, umax, xmin, xmax les fonctions de contraintes de bornes:\n",
    "umin = t -> \n",
    "umax = t -> \n",
    "xmin = t -> \n",
    "xmax = t -> \n",
    "# con1 est le membre de droite de la première EDO, con2 pour la deuxième\n",
    "con1(x₁, x₂, u) = \n",
    "con2(x₁, x₂, u) = \n",
    "# f est la fonction objectif sous l'intégrale. Avec PDENLPModels, on ne peux pas ajouter l'instant finale.\n",
    "# Mais on peut créer une fonction δ(t) = 0 si t < 0.99 et 1 sinon.\n",
    "δ(t) = t[1] > 0.999 ? 1. : 0. #Dirac of 1\n",
    "function f(x, u)\n",
    "  x₁, x₂ = x\n",
    "  - (δ * x₂)\n",
    "end\n",
    "nlp = GridapOptimalControl2DNLPModel(f, con1, con2, domain, n, x0 = x0, xf = xf, umin = umin, umax = umax, xmin = xmin, xmax = xmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résoudre le problème avec Ipopt et découper le résultat dans les vecteurs $x₁, x₂, u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ipopt(nlp, print_level =0, dual_inf_tol = 1e-10)\n",
    "\n",
    "nn = Integer((nlp.pdemeta.nvar_pde+1)/2)\n",
    "x₁, x₂, u = stats.solution[1:nn-1], stats.solution[nn:2*nn-1], stats.solution[2*nn:end]\n",
    "\n",
    "@test length(x₁) + length(x₂) == nlp.pdemeta.nvar_pde\n",
    "@test length(u) == nlp.pdemeta.nvar_con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afficher les états et le contrôle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p₁ = stats.multipliers[1:length(x₁)]\n",
    "# PDENLPModels.adjoint_function(domain, n, p₁)\n",
    "# cf. exercices précédents pour le domain et n.\n",
    "# p₁ est le vecteur de multiplicateur de Lagrange rendu pour la 1ère contrainte\n",
    "adjoint1 = PDENLPModels.adjoint_function() # à compléter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p₂ = stats.multipliers[length(x₁)+1:end]\n",
    "# function adjoint_function_final_condition(domain, n, p₂, 0.0)\n",
    "# cf. exercice précédent.\n",
    "adjoint2 = adjoint_function_final_condition() # à compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Convergence en n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommencer le processus (avec une boucle) pour observer la convergence du contrôle pour plusieurs valeurs de n (100, 500, 1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3: Git/Github, Pull request, OptimizationProblems\n",
    "\n",
    "L'objectif de cet exercice est de compléter votre implémentation d'un problème d'optimisation et d'ouvrir une \"Pull Request\" pour l'ajouter au package `OptimizationProblems.jl`.\n",
    "\n",
    "A tout moment, n'hésitez pas à demander de l'aide sur Zulip sur cette partie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 1: Compléter l'implémentation des problèmes\n",
    "\n",
    "Dans le rapport du Lab2, vous avez choisi un problème d'optimisation à modéliser (merci de le reprendre :) ).\n",
    "\n",
    "- [ ] Créer une fonction qui crée un modèle JuMP du problème que vous avez choisi. Vous pouvez suivre le modèle de la fonction `arglina` ici https://github.com/JuliaSmoothOptimizers/OptimizationProblems.jl/blob/main/src/PureJuMP/arglina.jl\n",
    "- [ ] Créer une fonction qui crée un modèle ADNLPModel du problème que vous avez choisi. Vous pouvez suivre le modèle de la fonction `arglina` ici https://github.com/JuliaSmoothOptimizers/OptimizationProblems.jl/blob/main/src/ADNLPProblems/arglina.jl\n",
    "\n",
    "Quand vous pensez avoir fini, merci de confirmer l'implémentation des deux problèmes avec le professeur.\n",
    "\n",
    "A noter que les problèmes en version `ADNLPModels` ont un kwargs `type`, car ces problèmes peuvent être formulés sous plusieurs format, cf. exemple ci-dessous. Demandez un coup de main si difficultés de ce côté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ADNLPModels, OptimizationProblems.ADNLPProblems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = arglina(type = Val(Float32))\n",
    "obj(nlp, nlp.meta.x0) # renvoie un nombre en Float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = arglina()\n",
    "obj(nlp, nlp.meta.x0) # par défaut on utilise Float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 2: Clone & fork\n",
    "\n",
    "Afin de faire une proposition de modification au package `OptimizationProblems.jl` vous allez devoir \"cloner\" ce package sur votre compte github et ouvrir une nouvelle branche où ajouter la modification.\n",
    "\n",
    "- [ ] Aller sur https://github.com/JuliaSmoothOptimizers/OptimizationProblems.jl et cliquer sur \"Fork\" en haut à droite de l'écran.\n",
    "- [ ] En suivant les indications du README du lab1 ici https://github.com/tmigot/MTH8408/tree/main/lab1 cloner la version sur votre compte github.\n",
    "- [ ] En suivant les inditions du README du lab2 ici https://github.com/tmigot/MTH8408/tree/main/lab2 ouvrir une nouvelle branche de travail. (en général on essaye d'éviter de travailler directement sur la branche `main`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 3: Modifier le package et mise en ligne\n",
    "- [ ] Sur votre branch local modifier le dépot en suivant les indications https://juliasmoothoptimizers.github.io/OptimizationProblems.jl/dev/contributing/\n",
    "- [ ] Une fois les modifications satisfaisantes faire un `git push origin nom_de_votre_branch` pour mettre en ligne vos modifications.\n",
    "- [ ] Checker vos modifications avec le professeur.\n",
    "- [ ] Ouvrir la Pull Request!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
