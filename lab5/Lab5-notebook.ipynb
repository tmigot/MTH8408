{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MTH8408 : Méthodes d'optimisation et contrôle optimal\n",
    " ## Laboratoire 5: Optimisation avec contraintes et calcul variationnel\n",
    "Tangi Migot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Krylov, LinearAlgebra, Logging, NLPModels, NLPModelsIpopt, Printf, SolverCore, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PDENLPModels, Gridap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelques commentaires en Julia\n",
    "\n",
    "### Les kwargs: choix optionnels\n",
    "\n",
    "Dans le projet du dernier labo, une des questions demandait d'ajouter une option pour utiliser la fonction `lsmr` ou `lsqr`. C'est le cas typique d'arguments optionnels:\n",
    "- On veut proposer un choix par défaut à l'utilisateur, par exemple `lsqr`;\n",
    "- On veut laisser la possibilité à l'utilisateur de changer;\n",
    "- On voudrait aussi pouvoir ajouter d'autres par la suite (sans avoir à tout modifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dsol (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function dsol(A, b, ϵ; solver :: Function = lsqr)\n",
    "    (d, stats) = solver(A, b, atol = ϵ)\n",
    "    return d\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A noter que l'on donne des valeurs par défaut aux arguments qui apparaissent après le `;`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1: Pénalité quadratique pour les ADNLPModels\n",
    "\n",
    "Dans cet exercice, on va étudier une version simple d'une méthode de pénalité quadratique pour les problèmes d'optimisation avec contraintes d'égalité.\n",
    "```math\n",
    "min f(x) s.à c(x) = 0.\n",
    "```\n",
    "Dans les labos précédents, on a déjà utilisé un NLPModel particulier, le ADNLPModel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADNLPModel - Model with automatic differentiation backend ADNLPModels.ForwardDiffAD{ForwardDiff.GradientConfig{ForwardDiff.Tag{typeof(fH), Float64}, Float64, 2, Vector{ForwardDiff.Dual{ForwardDiff.Tag{typeof(fH), Float64}, Float64, 2}}}}(3, 2, ForwardDiff.GradientConfig{ForwardDiff.Tag{typeof(fH), Float64}, Float64, 2, Vector{ForwardDiff.Dual{ForwardDiff.Tag{typeof(fH), Float64}, Float64, 2}}}((Partials(1.0, 0.0), Partials(0.0, 1.0)), ForwardDiff.Dual{ForwardDiff.Tag{typeof(fH), Float64}, Float64, 2}[Dual{ForwardDiff.Tag{typeof(fH), Float64}}(0.0,6.95176457205923e-310,6.9517648938691e-310), Dual{ForwardDiff.Tag{typeof(fH), Float64}}(0.0,6.95176457205923e-310,6.951764570645e-310)]))\n",
       "  Problem name: Generic\n",
       "   All variables: ████████████████████ 2      All constraints: ████████████████████ 1     \n",
       "            free: ████████████████████ 2                 free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "         low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ████████████████████ 1     \n",
       "          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "            nnzh: (  0.00% sparsity)   3               linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "                                                    nonlinear: ████████████████████ 1     \n",
       "                                                         nnzj: (  0.00% sparsity)   2     \n",
       "\n",
       "  Counters:\n",
       "             obj: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 grad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 cons: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "        cons_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             cons_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 jcon: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           jgrad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                  jac: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              jac_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "         jac_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                jprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0            jprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "       jprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jtprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0           jtprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "      jtprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 hess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                hprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n",
       "           jhess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jhprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using ADNLPModels, LinearAlgebra, Test\n",
    "fH(x) = (x[2]+x[1].^2-11)^2 + (x[1]+x[2].^2-7)^2\n",
    "x0H = [10., 20.]\n",
    "cH(x) = [x[1]-1]\n",
    "himmelblau = ADNLPModel(fH, x0H, cH, [0.], [0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention: dans toute la suite de l'exercice on suppose que les bornes sur les contraintes `nlp.meta.lcon` et `nlp.meta.ucon` sont 0 pour simplifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Transformer un ADNLPModel en un problème pénalisé\n",
    "Coder la fonction `quad_penalty_adnlp` qui prend en entrée un ADNLPModel, et un paramètre ρ et qui retourne un nouveau ADNLPModel qui correspond au problème sans contrainte:\n",
    "$$\n",
    "\\min_x f(x) + \\frac{\\rho}{2}\\|c(x)\\|^2.\n",
    "$$\n",
    "Remarque: on peut accèder aux fonctions f et c par `nlp.f` et `nlp.c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quad_penalty_adnlp (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function quad_penalty_adnlp(nlp :: ADNLPModel, ρ :: Real)\n",
    "    # TODO\n",
    "    f_quad(x) = nlp.f(x) + (ρ / 2) * nlp.c(x)' * nlp.c(x)\n",
    "    # f_quad(x) = nlp.f(x) + (ρ / 2) * (norm(nlp.c(x))^2)\n",
    "    x0_quad = nlp.meta.x0\n",
    "    nlp_quad = ADNLPModel(f_quad, x0_quad)\n",
    "    return nlp_quad\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Faire des tests pour vérifier que ça fonctionne.\n",
    "fH(x) = (x[2]+x[1].^2-11).^2+(x[1]+x[2].^2-7).^2\n",
    "x0H = [10., 20.]\n",
    "himmelblau = ADNLPModel(fH, x0H)\n",
    "\n",
    "himmelblau_quad = quad_penalty_adnlp(himmelblau, 1)\n",
    "@test himmelblau_quad.meta.ncon == 0\n",
    "@test obj(himmelblau_quad, zeros(2)) == 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ajouter au moins un autre test similaire avec des contraintes.\n",
    "using ADNLPModels, LinearAlgebra, Test\n",
    "fH(x) = (x[2]+x[1].^2-11)^2 + (x[1]+x[2].^2-7)^2\n",
    "x0H = [10., 20.]\n",
    "cH(x) = [x[1]-1]\n",
    "himmelblau_1 = ADNLPModel(fH, x0H, cH, [0.], [0.])\n",
    "\n",
    "himmelblau_1_quad = quad_penalty_adnlp(himmelblau_1, 1)\n",
    "@test himmelblau_1_quad.meta.ncon == 0\n",
    "@test obj(himmelblau_1_quad, zeros(2)) == 170.5\n",
    "@test obj(himmelblau_1_quad, ones(2)) == fH([1., 1.]) + cH([1.])[1] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ajouter un test au cas ou `nlp.meta.lcon` ou `nlp.meta.ucon` ont des composantes differentes de 0.\n",
    "using ADNLPModels, LinearAlgebra, Test\n",
    "fH(x) = (x[2]+x[1].^2-11)^2 + (x[1]+x[2].^2-7)^2\n",
    "x0H = [10., 20.]\n",
    "cH(x) = [x[1]-1]\n",
    "himmelblau_2 = ADNLPModel(fH, x0H, cH, [1.], [2.])\n",
    "\n",
    "himmelblau_2_quad = quad_penalty_adnlp(himmelblau_2, 1)\n",
    "@test himmelblau_2_quad.meta.ncon == 0\n",
    "@test obj(himmelblau_2_quad, zeros(2)) == 170.5\n",
    "@test obj(himmelblau_2_quad, ones(2)) == fH([1., 1.]) + cH([1.])[1] / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: KKT\n",
    "Coder une fonction `KKT_eq_constraint(nlp :: AbstractNLPModel, x, λ)` qui vérifie si le point `x` avec multiplicateur de Lagrange `λ` satisfait les conditions KKT d'un problème avec contraintes d'égalités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KKT_eq_constraint (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function KKT_eq_constraint(nlp :: AbstractNLPModel, x, λ)\n",
    "   # TODO\n",
    "   KKT = grad(nlp, x) + jac(nlp, x)' * λ\n",
    "   ϵ = 1e-3\n",
    "   if norm(KKT) <= ϵ && norm(nlp.c(x)) <= ϵ\n",
    "      return true\n",
    "   else\n",
    "      return false\n",
    "   end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×1 Matrix{Float64}:\n",
       " -13.0\n",
       " -22.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test\n",
    "fH(x) = (x[2]+x[1].^2-11)^2 + (x[1]+x[2].^2-7)^2\n",
    "x0H = [10., 20.]\n",
    "cH(x) = [x[1]-1]\n",
    "himmelblau_3 = ADNLPModel(fH, x0H, cH, [0.], [0.])\n",
    "\n",
    "@test KKT_eq_constraint(himmelblau_3, zeros(2), 1) == false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: méthode de pénalité quadratique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NLPModelsIpopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quad_penalty (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function quad_penalty(nlp      :: ADNLPModel, #Note que ça ne marche pas pour tous les NLPModel! \n",
    "                      x        :: AbstractVector; \n",
    "                      ϵ        :: AbstractFloat = 1e-3,\n",
    "                      η        :: AbstractFloat = 1e6, \n",
    "                      σ        :: AbstractFloat = 2.0,\n",
    "                      max_eval :: Int = 1_000, \n",
    "                      max_time :: AbstractFloat = 60.,\n",
    "                      max_iter :: Int = typemax(Int64)\n",
    "                      )\n",
    "    ##### Initialiser cx et gx au point x;\n",
    "    # cx = nlp.c(x)       # Initialiser la violation des contraintes\n",
    "    cx = nlp.c(x)\n",
    "    gx = grad(nlp, x)   # Initialiser le gradient\n",
    "    ######################################################\n",
    "    normcx = normcx_old = norm(cx)\n",
    "\n",
    "    ρ = 1.\n",
    "\n",
    "    iter = 0    \n",
    "\n",
    "    el_time = 0.0\n",
    "    tired   = neval_cons(nlp) > max_eval || el_time > max_time\n",
    "    status  = :unknown\n",
    "\n",
    "    start_time = time()\n",
    "    too_small  = false\n",
    "    normdual   = norm(gx) #exceptionnellement on ne va pas vérifier toute l'optimalité au début.\n",
    "    optimal    = max(normcx, normdual) ≤ ϵ\n",
    "    \n",
    "    nlp_quad   = quad_penalty_adnlp(nlp, ρ)\n",
    "\n",
    "    @info log_header([:iter, :nf, :primal, :status, :nd, :Δ],\n",
    "    [Int, Int, Float64, String, Float64, Float64],\n",
    "    hdr_override=Dict(:nf => \"#F\", :primal => \"‖F(x)‖\", :nd => \"‖d‖\"))\n",
    "\n",
    "    while !(optimal || tired || too_small)\n",
    "\n",
    "        #Appeler Ipopt pour résoudre le problème pénalisé en partant du point x0 = x.\n",
    "        #utiliser l'option print_level = 0 pour enlever les affichages d'ipopt.\n",
    "        stats = ipopt(nlp_quad, x0 = x, print_level = 0)\n",
    "        ################################################\n",
    "      \n",
    "        if stats.status == :first_order\n",
    "            ###### Mettre à jour cx avec la solution renvoyé par Ipopt\n",
    "            x = stats.solution\n",
    "            cx = nlp.c(x)\n",
    "            ##########################################################\n",
    "            normcx_old = normcx\n",
    "            normcx = norm(cx)\n",
    "        end\n",
    "        \n",
    "        if normcx_old > 0.95 * normcx\n",
    "            ρ *= σ\n",
    "        end\n",
    "\n",
    "        @info log_row(Any[iter, neval_cons(nlp), normcx, stats.status])\n",
    "        \n",
    "        nlp_quad   = quad_penalty_adnlp(nlp, ρ)\n",
    "\n",
    "        el_time      = time() - start_time\n",
    "        iter   += 1\n",
    "        many_evals   = neval_cons(nlp) > max_eval\n",
    "        iter_limit   = iter > max_iter\n",
    "        tired        = many_evals || el_time > max_time || iter_limit || ρ ≥ η\n",
    "        ##### Utiliser la réalisabilité dual renvoyé par Ipopt pour `normdual`\n",
    "        normdual     = stats.dual_feas\n",
    "        ###################################################################\n",
    "        optimal      = max(normcx, normdual) ≤ ϵ\n",
    "    end\n",
    "\n",
    "    status = if optimal \n",
    "        :first_order\n",
    "    elseif tired\n",
    "        if neval_cons(nlp) > max_eval\n",
    "            :max_eval\n",
    "        elseif el_time > max_time\n",
    "            :max_time\n",
    "        elseif iter > max_iter\n",
    "            :max_iter\n",
    "        else\n",
    "            :unknown_tired\n",
    "        end\n",
    "    elseif too_small\n",
    "        :stalled\n",
    "    else\n",
    "        :unknown\n",
    "    end\n",
    "\n",
    "    return GenericExecutionStats(nlp, status = status, solution = x,\n",
    "                                 objective = obj(nlp, x),\n",
    "                                 primal_feas = normcx,\n",
    "                                 dual_feas = normdual,\n",
    "                                 iter = iter, \n",
    "                                 elapsed_time = el_time,\n",
    "                                 solver_specific = Dict(:penalty => ρ))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info:   iter      #F    ‖F(x)‖           status       ‖d‖         Δ  \n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:32\n",
      "┌ Info:      0       0   2.0e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      1       0   2.0e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      2       0   1.9e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info:      3       0   1.9e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      4       0   1.7e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      5       0   1.5e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      6       0   1.1e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      7       0   5.5e-01      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      8       0   2.4e-01      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      9       0   1.1e-01      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     10       0   5.4e-02      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     11       0   2.6e-02      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     12       0   1.3e-02      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     13       0   6.5e-03      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     14       0   3.2e-03      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     15       0   1.6e-03      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     16       0   8.1e-04      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using ADNLPModels, LinearAlgebra, Test\n",
    "fH(x) = (x[2]+x[1].^2-11)^2 + (x[1]+x[2].^2-7)^2\n",
    "x0H = [10., 20.]\n",
    "cH(x) = [x[1]-1]\n",
    "himmelblau = ADNLPModel(fH, x0H, cH, [0.], [0.])\n",
    "\n",
    "#Faire des tests pour vérifier que ça fonctionne.\n",
    "stats = quad_penalty(himmelblau, 2ones(2))\n",
    "@test stats.status == :first_order\n",
    "@test stats.solution ≈ [1.0008083416169895, 2.709969135758311]\n",
    "@test norm(cons(himmelblau, stats.solution)) ≈ 0. atol=1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifier que la solution rendue vérifie les conditions KKT avec la fonction de la question précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info:   iter      #F    ‖F(x)‖           status       ‖d‖         Δ  \n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info:      0       0   2.0e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      1       0   2.0e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      2       0   1.9e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      3       0   1.9e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      4       0   1.7e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      5       0   1.5e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      6       0   1.1e+00      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      7       0   5.5e-01      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      8       0   2.4e-01      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:      9       0   1.1e-01      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     10       0   5.4e-02      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     11       0   2.6e-02      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     12       0   1.3e-02      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     13       0   6.5e-03      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info:     14       0   3.2e-03      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     15       0   1.6e-03      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n",
      "┌ Info:     16       0   8.1e-04      first_order\n",
      "└ @ Main c:\\Users\\Goglu\\GitClones\\MTH8408\\lab5\\Lab5-notebook.ipynb:56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "using ADNLPModels, LinearAlgebra, Test\n",
    "fH(x) = (x[2]+x[1].^2-11)^2 + (x[1]+x[2].^2-7)^2\n",
    "x0H = [10., 20.]\n",
    "cH(x) = [x[1]-1]\n",
    "himmelblau = ADNLPModel(fH, x0H, cH, [0.], [0.])\n",
    "\n",
    "stats = quad_penalty(himmelblau, 2ones(2))\n",
    "@test KKT_eq_constraint(himmelblau, stats.solution, - Matrix(jac(himmelblau, stats.solution)') \\ grad(himmelblau, stats.solution)) == true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:  | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Simple problem | \u001b[32m   4  \u001b[39m\u001b[36m    4  \u001b[39m\u001b[0m4.9s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0m\u001b[1mTest Summary:          | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "Rosenbrock with ∑x = 1 | \u001b[32m   3  \u001b[39m\u001b[36m    3  \u001b[39m\u001b[0m0.7s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "HS6           | \u001b[32m   3  \u001b[39m\u001b[36m    3  \u001b[39m\u001b[0m0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary: | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "HS7           | \u001b[32m   3  \u001b[39m\u001b[36m    3  \u001b[39m\u001b[0m0.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Test.DefaultTestSet(\"HS7\", Any[], 3, false, false, true, 1.678723159607e9, 1.678723160223e9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fichier de tests à demander.\n",
    "tol = 1e-3\n",
    "@testset \"Simple problem\" begin\n",
    "    n = 10\n",
    "    nlp = ADNLPModel(x->dot(x, x), zeros(n),\n",
    "                     x->[sum(x) - 1], zeros(1), zeros(1))\n",
    "\n",
    "    stats = with_logger(NullLogger()) do\n",
    "      quad_penalty(nlp, nlp.meta.x0, ϵ=1e-6)\n",
    "    end\n",
    "    dual, primal, status = stats.dual_feas, stats.primal_feas, stats.status\n",
    "    @test norm(n * stats.solution - ones(n)) < tol\n",
    "    @test dual < tol\n",
    "    @test primal < tol\n",
    "    @test status == :first_order\n",
    "end\n",
    "\n",
    "@testset \"Rosenbrock with ∑x = 1\" begin\n",
    "    nlp = ADNLPModel(x->(x[1] - 1.0)^2 + 100 * (x[2] - x[1]^2)^2, \n",
    "                     [-1.2; 1.0],\n",
    "                     x->[sum(x)-1], [0.0], [0.0])\n",
    "\n",
    "    stats = with_logger(NullLogger()) do\n",
    "      quad_penalty(nlp, nlp.meta.x0)\n",
    "    end\n",
    "    dual, primal, status = stats.dual_feas, stats.primal_feas, stats.status\n",
    "    @test dual < tol#1e-6\n",
    "    @test primal < tol\n",
    "    @test status == :first_order\n",
    "end\n",
    "\n",
    "@testset \"HS6\" begin\n",
    "    nlp = ADNLPModel(x->(1 - x[1])^2, [-1.2; 1.0],\n",
    "                     x->[10 * (x[2] - x[1]^2)], [0.0], [0.0])\n",
    "\n",
    "    stats = with_logger(NullLogger()) do\n",
    "      quad_penalty(nlp, nlp.meta.x0)\n",
    "    end\n",
    "    dual, primal, status = stats.dual_feas, stats.primal_feas, stats.status\n",
    "    @test dual < tol\n",
    "    @test primal < tol\n",
    "    @test status == :first_order\n",
    "end\n",
    "\n",
    "@testset \"HS7\" begin\n",
    "    nlp = ADNLPModel(x->log(1 + x[1]^2) - x[2], \n",
    "                     [2.0; 2.0],\n",
    "                     x->[(1 + x[1]^2)^2 + x[2]^2 - 4], [0.0], [0.0])\n",
    "\n",
    "    stats = with_logger(NullLogger()) do\n",
    "      quad_penalty(nlp, nlp.meta.x0)\n",
    "    end\n",
    "    dual, primal, status = stats.dual_feas, stats.primal_feas, stats.status\n",
    "    @test dual < tol\n",
    "    @test primal < tol\n",
    "    @test status == :first_order\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2: Calcul Variationnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exercice, on considère le problème de calcul variationnel suivant:\n",
    "$$\n",
    "\\min \\int_0^1 (\\dot{x}(t)^2+2x(t)^2)e^t dt, \\quad x(0)=0, x(1)=e - e^{-2}\n",
    "$$\n",
    "\n",
    "modélisé avec `PDENLPModels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv_model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function cv_model(n :: Int)\n",
    "\n",
    "  domain = (0,1) # set the domain\n",
    "  partition = n\n",
    "  model = CartesianDiscreteModel(domain,partition) # set discretization\n",
    "    \n",
    "  labels = get_face_labeling(model)\n",
    "  add_tag_from_tags!(labels,\"diri1\",[2])\n",
    "  add_tag_from_tags!(labels,\"diri0\",[1]) # boundary conditions\n",
    "\n",
    "  order=1\n",
    "  valuetype=Float64\n",
    "  reffe = ReferenceFE(lagrangian, valuetype, order)\n",
    "  V0 = TestFESpace(model, reffe; conformity=:H1, dirichlet_tags=[\"diri0\",\"diri1\"])\n",
    "  U = TrialFESpace(V0,[0., exp(1)-exp(-2)])\n",
    "\n",
    "  trian = Triangulation(model)\n",
    "  degree = 2\n",
    "  dΩ = Measure(trian,degree) # integration machinery\n",
    "\n",
    "  # Our objective function\n",
    "  w(x) = exp(x[1])\n",
    "  function f(y)\n",
    "    ∫((∇(y)⊙∇(y) + 2 * y * y) * w) * dΩ\n",
    "  end\n",
    "\n",
    "  xin = zeros(Gridap.FESpaces.num_free_dofs(U))\n",
    "  nlp = GridapPDENLPModel(xin, f, trian, U, V0)\n",
    "  return nlp\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Résoudre\n",
    "Résoudre le NLPModel généré par la fonction `cv_model` pour `n = 16` avec `ipopt` et afficher la solution (attention la solution rendue ne contient pas les valeurs aux bords qu'il faut rajouter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.14.4, running with linear solver MUMPS 5.5.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:       44\n",
      "\n",
      "Total number of variables............................:       15\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  2.8202747e+02 0.00e+00 1.00e+02  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  2.0987074e+01 0.00e+00 3.02e-14  -1.0 2.40e+00    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 1\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   9.6484800135597375e+00    2.0987074475792042e+01\n",
      "Dual infeasibility......:   3.0216136547373433e-14    6.5725203057809267e-14\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   3.0216136547373433e-14    6.5725203057809267e-14\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 2\n",
      "Number of objective gradient evaluations             = 2\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 1\n",
      "Total seconds in IPOPT                               = 7.386\n",
      "\n",
      "EXIT: Optimal Solution Found.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Execution stats: first-order stationary\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "stats = ipopt(cv_model(16))\n",
    "x16 = vcat([0], stats.solution, [exp(1) - exp(-2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Convergence en `n`\n",
    "Afficher sur un même graphique la solution obtenue par `ipopt` pour plusieurs valeurs de `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.14.4, running with linear solver MUMPS 5.5.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:       20\n",
      "\n",
      "Total number of variables............................:        7\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  1.3784624e+02 0.00e+00 1.00e+02  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  2.0990353e+01 0.00e+00 3.89e-14  -1.0 2.22e+00    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 1\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   1.9981056068992515e+01    2.0990352762067296e+01\n",
      "Dual infeasibility......:   3.8891684108660893e-14    4.0856207306205761e-14\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   3.8891684108660893e-14    4.0856207306205761e-14\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 2\n",
      "Number of objective gradient evaluations             = 2\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 1\n",
      "Total seconds in IPOPT                               = 1.104\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "This is Ipopt version 3.14.4, running with linear solver MUMPS 5.5.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:       44\n",
      "\n",
      "Total number of variables............................:       15\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  2.8202747e+02 0.00e+00 1.00e+02  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  2.0987074e+01 0.00e+00 3.02e-14  -1.0 2.40e+00    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 1\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   9.6484800135597375e+00    2.0987074475792042e+01\n",
      "Dual infeasibility......:   3.0216136547373433e-14    6.5725203057809267e-14\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   3.0216136547373433e-14    6.5725203057809267e-14\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 2\n",
      "Number of objective gradient evaluations             = 2\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 1\n",
      "Total seconds in IPOPT                               = 0.062\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "This is Ipopt version 3.14.4, running with linear solver MUMPS 5.5.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:       92\n",
      "\n",
      "Total number of variables............................:       31\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  5.7173131e+02 0.00e+00 1.00e+02  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  2.0986242e+01 0.00e+00 3.86e-14  -1.0 2.49e+00    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 1\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   4.7451983295117293e+00    2.0986241596125360e+01\n",
      "Dual infeasibility......:   3.8558590158207547e-14    1.7053025658242404e-13\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   3.8558590158207547e-14    1.7053025658242404e-13\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 2\n",
      "Number of objective gradient evaluations             = 2\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 1\n",
      "Total seconds in IPOPT                               = 0.061\n",
      "\n",
      "EXIT: Optimal Solution Found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "using Plots\n",
    "\n",
    "stats8 = ipopt(cv_model(8))\n",
    "x8 = vcat([0], stats8.solution, [exp(1) - exp(-2)])\n",
    "\n",
    "stats16 = ipopt(cv_model(16))\n",
    "x16 = vcat([0], stats16.solution, [exp(1) - exp(-2)])\n",
    "\n",
    "stats32 = ipopt(cv_model(32))\n",
    "x32 = vcat([0], stats32.solution, [exp(1) - exp(-2)])\n",
    "\n",
    "plot(x8, x16, x32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Comparer à la solution exacte\n",
    "\n",
    "La solution exacte est $x(t)=e^t - e^{-2t}$ et la valeur optimale est $e^3 - 2e^{-3}+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.4",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
